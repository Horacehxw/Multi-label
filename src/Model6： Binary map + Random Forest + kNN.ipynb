{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M6ï¼š Binary map + Random Forest + kNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load GPU Faiss: No module named swigfaiss_gpu\n",
      "Faiss falling back to CPU-only.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import os\n",
    "import data_util\n",
    "import BMapModel\n",
    "#from data_util import DataPoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import faiss\n",
    "import util\n",
    "import scipy\n",
    "# import joblib # version incompatibel with sklearn's joblib and can't load the previous model\n",
    "\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "from sklearn.externals import joblib # store classifiers\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # convert y to {0,1}^L\n",
    "from sklearn.preprocessing import StandardScaler # normalize features \n",
    "from sklearn.feature_extraction import DictVectorizer # extract feature vector to x\n",
    "from numpy.random import normal # generate transforming matrix\n",
    "from sklearn.neighbors import KDTree #KDTree for fast kNN search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from joblib import Parallel, delayed # Multitread\n",
    "from pytictoc import TicToc\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data:\r\n",
      "AmazonCat\t   Bibtex\t   Eurlex     README_Datasets\r\n",
      "AmazonCat-14K\t   Delicious\t   Mediamill  Wiki10\r\n",
      "AmazonCat-14K.zip  DeliciousLarge  RCV1-x     XMLDatasetRead\r\n",
      "\r\n",
      "../data/AmazonCat:\r\n",
      "amazonCat_test.txt  amazonCat_train.txt  X_te.npz  X_tr.npz  Y_te.npz  Y_tr.npz\r\n",
      "\r\n",
      "../data/AmazonCat-14K:\r\n",
      "amazonCat-14K_test.txt\t X_te.npz  Y_te.npz\r\n",
      "amazonCat-14K_train.txt  X_tr.npz  Y_tr.npz\r\n",
      "\r\n",
      "../data/Bibtex:\r\n",
      "Bibtex_data.txt     bibtex_tstSplit.txt  X_tr.npz  Y_tr.npz\r\n",
      "bibtex_trSplit.txt  X_te.npz\t\t Y_te.npz\r\n",
      "\r\n",
      "../data/Delicious:\r\n",
      "Delicious_data.txt\tX_te.npz  X_tr.pkl  Y_tr.npz\r\n",
      "delicious_trSplit.txt\tX_te.pkl  Y_te.npz  Y_tr.pkl\r\n",
      "delicious_tstSplit.txt\tX_tr.npz  Y_te.pkl\r\n",
      "\r\n",
      "../data/DeliciousLarge:\r\n",
      "deliciousLarge_test.txt   X_te.npz  Y_te.npz\r\n",
      "deliciousLarge_train.txt  X_tr.npz  Y_tr.npz\r\n",
      "\r\n",
      "../data/Eurlex:\r\n",
      "eurlex_test.txt  eurlex_train.txt  X_te.npz  X_tr.npz  Y_te.npz  Y_tr.npz\r\n",
      "\r\n",
      "../data/Mediamill:\r\n",
      "Mediamill_data.txt  mediamill_trSplit.txt  mediamill_tstSplit.txt\r\n",
      "\r\n",
      "../data/RCV1-x:\r\n",
      "rcv1x_test.txt\t X_te.npz  X_tr.npz  Y_te.npz  Y_tr.npz\r\n",
      "rcv1x_train.txt  X_te.pkl  X_tr.pkl  Y_te.pkl  Y_tr.pkl\r\n",
      "\r\n",
      "../data/Wiki10:\r\n",
      "wiki10_test.txt   X_te.npz  X_tr.npz  Y_te.npz\tY_tr.npz\r\n",
      "wiki10_train.txt  X_te.pkl  X_tr.pkl  Y_te.pkl\tY_tr.pkl\r\n",
      "\r\n",
      "../data/XMLDatasetRead:\r\n",
      "XMLDatasetRead\r\n",
      "\r\n",
      "../data/XMLDatasetRead/XMLDatasetRead:\r\n",
      "ReadData_Matlab  README_Datasets\r\n",
      "\r\n",
      "../data/XMLDatasetRead/XMLDatasetRead/ReadData_Matlab:\r\n",
      "make.m\tread_data.cpp  README.txt  write_data.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m../data/Delicious/Delicious_data.txt\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/Delicious/Delicious_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "model_dir = \"../model/model6\"\n",
    "#train_filename = \"/AmazonCat-14K/amazonCat-14K_train.txt\"\n",
    "#test_filename = \"/AmazonCat-14K/amazonCat-14K_test.txt\"\n",
    "#tr_split_file = \"/Bibtex/bibtex_trSplit.txt\"\n",
    "#te_split_file = \"/Bibtex/bibtex_tstSplit.txt\"\n",
    "\n",
    "path = \"/Delicious\"\n",
    "model_path = model_dir + path\n",
    "data_path = data_dir + path\n",
    "num_core = -1\n",
    "L_hat_ratio = 0.5 # useful when calculate L_hat = klogn*ratio\n",
    "L_hat = 100\n",
    "time = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tr_data, num_point, num_feature, num_label = data_util.read_file(data_dir+train_filename)\n",
    "#te_data, _, _, _ = data_util.read_file(data_dir+test_filename)\n",
    "#tr_split = data_util.split_data(data=tr_data, split_file=data_dir+tr_split_file)\n",
    "#te_split = data_util.split_data(data=tr_data, split_file=data_dir+te_split_file)\n",
    "#print(\"num_point={}, num_label={}, num_feature={}\".format(num_point, num_label, num_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "X_tr, Y_tr, X_te, Y_te = data_util.data_transform(tr_data, te_data, num_label)\n",
    "time.toc('data preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, x in zip(['X_tr', 'X_te', 'Y_tr', 'Y_te'], [X_tr, X_te, Y_tr, Y_te]):\n",
    "    save_npz(os.path.join(data_path, '{}.npz'.format(name)), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[X_tr, X_te, Y_tr, Y_te] = [load_npz(os.path.join(data_path, '{}.npz'.format(name)))\\\n",
    "                            for name in ['X_tr', 'X_te', 'Y_tr', 'Y_te']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12920, 500), (3185, 500), (12920, 983), (3185, 983))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: map to $\\hat L$ space and kNN search index\n",
    "\n",
    "We apply $$\\hat L = k \\log L$$ where $k$ indicates the sparsity of each label vector $y_i = \\{0,1\\}^L$. By default we choose k to be the 99.9% maximum sparsity to avoid extreme cases.\n",
    "\n",
    "The data in \"Eurlex\" contains $L = 5000$ labels, we are trying to map it into $\\hat L = 200$ space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.035371517027865"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_k = Y_tr.getnnz() / float(Y_tr.shape[0])\n",
    "avg_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = sorted([Y_tr[i, :].getnnz() for i in range(Y_tr.shape[0])], reverse=True)\\\n",
    "    [int(X_tr.shape[0]*0.01)]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L_hat = int(math.ceil(avg_k * math.log(Y_tr.shape[1], 2) * L_hat_ratio))\n",
    "L_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 0.413983 seconds.\n"
     ]
    }
   ],
   "source": [
    "time.tic()\n",
    "Z_tr = util.map_2_z(Y_tr, L_hat)\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12920, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4808877708978328"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sparsity in embedding space\n",
    "(Z_tr == 1).sum() / float(Z_tr.shape[0] * Z_tr.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Model\n",
    "\n",
    "#### 2.1 train binary classifiers on each bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=1)\n",
    "time.tic()\n",
    "clf.fit(X_tr, Z_tr)\n",
    "training_time = time.tocvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e41bccbbc5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'label0.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# only one classifiers, name for convention#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m         with _write_fileobject(filename, compress=(compress_method,\n\u001b[1;32m    479\u001b[0m                                                    compress_level)) as f:\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle_utils.pyc\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "joblib.dump(clf, os.path.join(model_path , 'label0.pkl'), compress=3)# only one classifiers, name for convention#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "clf = joblib.load(os.path.join(model_path , 'label0.pkl'))\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf # test if load successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.2 Store the lower degree space info for kNN\n",
    "\n",
    "We use opensource faiss library from FAIR to speedup the ANN(Approximate Nearest Neighbor) search.\n",
    "\n",
    "When dimension and data size is relatively small, we use the brute force kNN search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 0.003482 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# faiss brute force search\n",
    "nn_index = faiss.index_factory(Z_tr.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "time.tic()\n",
    "nn_index.add(Z_tr.astype('float32'))\n",
    "time.toc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```Python\n",
    "# index created by index factory, Approximate kNN search\n",
    "nn_index = faiss.index_factory(Z_tr.shape[1], \"IVF100,Flat\", faiss.METRIC_L2) # need train\n",
    "nn_index.train(Z_tr.astype('float32'))\n",
    "nn_index.add(Z_tr.astype('float32'))\n",
    "print \"nlist = {}\".format(nn_index.nlist) # number of clusters, only INF has this\n",
    "print \"nprobe = {}\".format(nn_index.nprobe)\n",
    "nn_index.nprobe = 1 # number of clusters to search through, only INF has this, need to be validate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Prediction and Validation\n",
    "\n",
    "test by RandomForest.predict and predict_prob to generate z_pred and then ues kNN to find y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, index=nn_index, \n",
    "                               Y_tr=Y_tr, model_path=model_path, num_core=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred = model.predict_y(X_te, vote=30, classifier='RandomForest') # 1 nearest neighbor\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred_p = model.predict_y(X_te,  vote=30, classifier='RandomForest', predict_prob=True) # 1 nearest neighbor\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util\n",
    "for i in np.arange(1,6,2):\n",
    "    print \"p@{} for classification:\\t {}\\n\".format(i, util.precision_at_k(Y_te, Y_pred, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in np.arange(1,6,2):\n",
    "    print \"p@{} for probability predict:\\t {}\\n\"\\\n",
    "        .format(i, util.precision_at_k(Y_te, Y_pred_p, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "z_prob = model.predict_prob_z(X_te)\n",
    "time.toc('predict prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "dist, ind = nn_index.search(z_prob.astype('float32'), 100)\n",
    "#time.toc('Approximate-kNN search with probe={}'.format(model.index.nprobe))\n",
    "time.toc('kNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred_t = np.array([np.sum([Y_tr[indij] for indij in indi], axis=0)\\\n",
    "                     for indi in ind])\n",
    "time.toc('weighted votes on kNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, Y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(vote)(indi, disti, True) for indi, disti in zip(ind, dist))\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result (vote = 100, kNN = brute force)\n",
    "\n",
    "|Large DataSet  |precision@k| RF Classification | RF predict prob | DiSMEC | SLEEK | FastXML\n",
    "|----| \n",
    "|RCV1-2k        |p@1        | 80.6              | 80.9            | *      | *     | * \n",
    "|               |p@2        | 68.0              | 68.2            | *      | *     | * \n",
    "|               |p@3        | 63.9              | 64.1            | *      | *     | *  \n",
    "|Wiki10-31k     |p@1        | 80.80             | 80.81           | 85.20  | **85.88** | 83.03 \n",
    "|               |p@3        | 62.74             | 64.65           | **74.60**  | 72.98 | 67.74  \n",
    "|               |p@5        | 54.91             | 56.54           | **65.90**  | 62.70 | 57.76 \n",
    "|Delicious-200k |p@1        | 38.63             | 39.92           | 45.50  | **47.85** | 43.07\n",
    "|               |p@3        | 35.83             | 36.89           | 38.70  | **42.21** | 38.66  \n",
    "|               |p@5        | 34.20             | 35.15           | 35.50  | **39.43** | 36.19 \n",
    "|AmazonCat-13k  |p@1        | 78.51             | 78.59           | 93.40  | 90.53 | 93.11\n",
    "|               |p@3        | 63.62             | 63.77           | 79.10  | 76.33 | 78.20  \n",
    "|               |p@5        | 48.72             | 48.66           | 64.10  | 61.52 | 63.41 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Small Dataset:\n",
    "\n",
    "|Small Dataset  |precision@k| RF Classification | RF predict prob | DiSMEC | SLEEK | FastXML\n",
    "|----| \n",
    "|Delicious      |p@1        | 63.17             | 64.27            | *      | **67.59** | 67.13\n",
    "|               |p@2        | 58.18             | 58.79            | *      | 61.38 | **62.33** \n",
    "|               |p@3        | 53.38             | 54.33            | *      | 56.56 | **58.62** \n",
    "|Bitex          |p@1        | 59.80             | 60.00            | *      | **65.08** | 63.46\n",
    "|(Voter=30)     |p@2        | 31.58             | 31.96            | *      | **39.64** | 39.22 \n",
    "|               |p@3        | 22.26             | 22.40            | *      | 28.87 | **29.14**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate_voter(voter, use_prob):\n",
    "    Y_pred = model.predict_y(X_te, vote=voter, classifier='RandomForest', \n",
    "                             predict_prob=use_prob)\n",
    "    return (util.precision_at_k(Y_te, Y_pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_at_k_votes_prob = Parallel(n_jobs=num_core)\\\n",
    "                    (delayed(validate_voter)(voter, True) for voter in np.arange(1, 151, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_at_k_votes = Parallel(n_jobs=num_core)\\\n",
    "                    (delayed(validate_voter)(voter, False) for voter in np.arange(1, 151, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(np.arange(1, 151, 10), p_at_k_votes_prob, label='pred_prob')\n",
    "plt.plot(np.arange(1, 151, 10), p_at_k_votes, label='pred')\n",
    "plt.xlabel('number of voters in kNN')\n",
    "plt.ylabel('p@1 score')\n",
    "plt.title('L_hat={}, RandomForest predict_prob, {}'.format(L_hat, train_filename))\n",
    "plt.legend()\n",
    "top = np.argmax(p_at_k_votes)\n",
    "(p_at_k_votes[top], top), (np.max(p_at_k_votes_prob), np.argmax(p_at_k_votes_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3 optimize hyperparameter\n",
    "use  k fold cross validation to optimize over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# validate the result with different L_hat under the same model\n",
    "def validate(L_hat, pk=1, vote=20, use_prob=False): # simple forkable parallel for loop body\n",
    "    from util import map_2_z\n",
    "    from util import precision_at_k\n",
    "\n",
    "   # for train_index, test_index in k_fold.split(X_tr):\n",
    "    x_train = X_tr\n",
    "    y_train = Y_tr\n",
    "    x_test = X_te\n",
    "    y_test = Y_te\n",
    "\n",
    "    # map and create kNN index\n",
    "    z_train = map_2_z(y_train, L_hat)\n",
    "    # faiss brute force search\n",
    "    knn_index = faiss.index_factory(z_train.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "    knn_index.add(z_train.astype('float32'))\n",
    "    #train clf\n",
    "    clf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "    clf.fit(x_train, z_train)\n",
    "    # construct model\n",
    "    model = BMapModel.BM_Predictor(Y_tr.shape[1], 1, index=knn_index, Y_tr=y_train)\n",
    "    model.clfs.append(clf)\n",
    "    #predict and calculate p@k score\n",
    "    y_pred = model.predict_y(x_test, vote=vote, weighted=True, classifier='RandomForest', predict_prob=use_prob)\n",
    "    # precision@pk\n",
    "    return precision_at_k(y_test, y_pred, k=pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize L_hat's value on the metric precision@k\n",
    "pk=1\n",
    "vote=100\n",
    "L_hat_range = range(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_hat_score = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(validate)(L_hat, pk, vote) for L_hat in L_hat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hat_score_prob = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(validate)(L_hat, pk, vote, True) for L_hat in L_hat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_down, = plt.plot(range(1,200), L_hat_score, label='random forest performance')\n",
    "plt.xlabel('L_hat')\n",
    "plt.ylabel('precision@{}'.format(pk))\n",
    "plt.title('Delicious validation on L_hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4 Bit Flip Probability\n",
    "the classifiers predict $\\hat z$ can be viewed as transmiting z from a BSC channel with some bit flip probability, this is actually representing the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hat, X_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_channel(X_te, Y_te):\n",
    "    z_te = util.map_2_z(Y_te, L_hat)\n",
    "    # use the classifers to predict z_hat\n",
    "    model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, model_path=model_path,)\n",
    "    z_pred = model.predict_z(X_te)\n",
    "    \n",
    "    hamming = []\n",
    "    for i in range(z_te.shape[0]):\n",
    "        hamming.append((z_pred[i]!=z_te[i]).sum())\n",
    "    return np.array(hamming) / float(z_te.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error = validate_channel(X_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(test_error, bins=20)\n",
    "plt.xlabel('error rate between z_te and z_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('Delicious: distribution of bit_flip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_error = validate_channel(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(training_error, bins=20)\n",
    "plt.xlabel('error rate between z_train and z_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('{}: distribution of training error'.format(train_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.5 Train and test model directly on the X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir_mirror = model_dir+\"_origin\"\n",
    "model_path_mirror = model_dir_mirror+path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)\n",
    "time.tic()\n",
    "classifier.fit(X=X_tr, y=Y_tr)\n",
    "time.toc()\n",
    "#joblib.dump(classifier, os.path.join(model_path_mirror , 'RandomForestClassifier.pkl'))# only one classifiers, name for convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier = joblib.load(os.path.join(model_path_mirror , 'RandomForestClassifier.pkl'))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "y_pred = classifier.predict(X_te)\n",
    "time.toc('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamming = []\n",
    "for i in range(y_pred.shape[0]):\n",
    "    hamming.append((y_pred[i]!=Y_te[i]).sum())\n",
    "hamming = np.array(hamming) / float(Y_te.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(hamming)\n",
    "plt.xlabel('error_rate')\n",
    "plt.ylabel('density')\n",
    "plt.title('test error rate distribution, {}, Randomforest, mean={}'.format(train_filename, hamming.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "y_pred_prob = classifier.predict_proba(X_te) #for every label there's a 2D (sample, output(2)) probability\n",
    "time.toc('predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = np.ascontiguousarray(np.array([prob[:, 1] for prob in y_pred_prob]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the precision@k of RandomForest.predict_prob training directly on X_tr and Y_tr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, y_prob, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "precit_prob + kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_tr_index = faiss.index_factory(Y_tr.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "Y_tr_index.add(Y_tr.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist, ind = Y_tr_index.search(y_prob.astype('float32'), 1)\n",
    "y_prob_vote = np.array([np.sum([Y_tr[ind[i][j]] for j in range(len(ind[i]))], axis=0) for i in range(len(ind))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, y_prob_vote, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_bits(message, p0, p1):\n",
    "    '''\n",
    "    randomly flip every \"1\" w/ prob p1, and every \"0\" w/ p0\n",
    "    '''\n",
    "    def flip(bit):\n",
    "        if bit==1 and np.random.rand()<p1:\n",
    "            bit = 0\n",
    "        if bit==0 and np.random.rand()<p0:\n",
    "            bit=1\n",
    "        return bit\n",
    "    np.random.seed(0)\n",
    "    return np.apply_along_axis(lambda bits: np.array([flip(bit) for bit in bits]), 0, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flip_bits(np.array([[1,0,1],[0,1,1]]), 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
