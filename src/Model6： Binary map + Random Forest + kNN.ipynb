{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M6ï¼š Binary map + Random Forest + kNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load GPU Faiss: No module named swigfaiss_gpu\n",
      "Faiss falling back to CPU-only.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import os\n",
    "import data_util\n",
    "import BMapModel\n",
    "#from data_util import DataPoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import faiss\n",
    "import util\n",
    "# import joblib # version incompatibel with sklearn's joblib and can't load the previous model\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib # store classifiers\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # convert y to {0,1}^L\n",
    "from sklearn.preprocessing import StandardScaler # normalize features \n",
    "from sklearn.feature_extraction import DictVectorizer # extract feature vector to x\n",
    "from numpy.random import normal # generate transforming matrix\n",
    "from sklearn.neighbors import KDTree #KDTree for fast kNN search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from joblib import Parallel, delayed # Multitread\n",
    "from pytictoc import TicToc\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data:\r\n",
      "AmazonCat  Delicious  Mediamill  README_Datasets  XMLDatasetRead\r\n",
      "Bibtex\t   Eurlex     RCV1-x\t Wiki10\r\n",
      "\r\n",
      "../data/AmazonCat:\r\n",
      "amazonCat_test.txt  amazonCat_train.txt\r\n",
      "\r\n",
      "../data/Bibtex:\r\n",
      "Bibtex_data.txt  bibtex_trSplit.txt  bibtex_tstSplit.txt\r\n",
      "\r\n",
      "../data/Delicious:\r\n",
      "Delicious_data.txt  delicious_trSplit.txt  delicious_tstSplit.txt\r\n",
      "\r\n",
      "../data/Eurlex:\r\n",
      "eurlex_test.txt  eurlex_train.txt\r\n",
      "\r\n",
      "../data/Mediamill:\r\n",
      "Mediamill_data.txt  mediamill_trSplit.txt  mediamill_tstSplit.txt\r\n",
      "\r\n",
      "../data/RCV1-x:\r\n",
      "rcv1x_test.txt\trcv1x_train.txt  X_te.pkl  X_tr.pkl  Y_te.pkl  Y_tr.pkl\r\n",
      "\r\n",
      "../data/Wiki10:\r\n",
      "wiki10_test.txt  wiki10_train.txt\r\n",
      "\r\n",
      "../data/XMLDatasetRead:\r\n",
      "XMLDatasetRead\r\n",
      "\r\n",
      "../data/XMLDatasetRead/XMLDatasetRead:\r\n",
      "ReadData_Matlab  README_Datasets\r\n",
      "\r\n",
      "../data/XMLDatasetRead/XMLDatasetRead/ReadData_Matlab:\r\n",
      "make.m\tread_data.cpp  README.txt  write_data.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m../data/RCV1-x/rcv1x_test.txt\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/RCV1-x/rcv1x_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "model_dir = \"../.model6\"\n",
    "train_filename = \"/RCV1-x/rcv1x_train.txt\"\n",
    "test_filename = \"/RCV1-x/rcv1x_test.txt\"\n",
    "#tr_split_file = \"/Delicious/delicious_trSplit.txt\"\n",
    "#te_split_file = \"/Delicious/delicious_tstSplit.txt\"\n",
    "\n",
    "path = os.path.dirname(train_filename)\n",
    "model_path = model_dir + path\n",
    "data_path = data_dir + path\n",
    "num_core = -1\n",
    "L_hat_ratio = 0.5 # useful when calculate L_hat = klogn*ratio\n",
    "L_hat = 100\n",
    "time = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_point=623847, num_label=2456, num_feature=47236\n"
     ]
    }
   ],
   "source": [
    "tr_data, num_point, num_feature, num_label = data_util.read_file(data_dir+train_filename)\n",
    "te_data, _, _, _ = data_util.read_file(data_dir+test_filename)\n",
    "#tr_split = data_util.split_data(data=tr_data, split_file=data_dir+tr_split_file)\n",
    "#te_split = data_util.split_data(data=tr_data, split_file=data_dir+te_split_file)\n",
    "print(\"num_point={}, num_label={}, num_feature={}\".format(num_point, num_label, num_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, Y_tr, X_te, Y_te = data_util.data_transform(tr_data, te_data, num_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/RCV1-x/Y_te.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_tr, os.path.join(data_path, 'X_tr.pkl'), compress=3)\n",
    "joblib.dump(X_te, os.path.join(data_path, 'X_te.pkl'), compress=3)\n",
    "joblib.dump(Y_tr, os.path.join(data_path, 'Y_tr.pkl'), compress=3)\n",
    "joblib.dump(Y_te, os.path.join(data_path, 'Y_te.pkl'), compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = joblib.load(os.path.join(data_path, 'X_tr.pkl'))\n",
    "Y_tr = joblib.load(os.path.join(data_path, 'Y_tr.pkl'))\n",
    "X_te = joblib.load(os.path.join(data_path, 'X_te.pkl'))\n",
    "Y_te = joblib.load(os.path.join(data_path, 'Y_te.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623847, 42315), (155962, 42315))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: map to $\\hat L$ space and kNN search index\n",
    "\n",
    "We apply $$\\hat L = k \\log L$$ where $k$ indicates the sparsity of each label vector $y_i = \\{0,1\\}^L$. By default we choose k to be the 99.9% maximum sparsity to avoid extreme cases.\n",
    "\n",
    "The data in \"Eurlex\" contains $L = 5000$ labels, we are trying to map it into $\\hat L = 200$ space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = sorted([Y.sum() for Y in Y_tr], reverse=True)[int(X_tr.shape[0]*0.01)]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_tr = util.map_2_z(Y_tr, L_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Model\n",
    "\n",
    "#### 2.1 train binary classifiers on each bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7fea22af97b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/horace...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7fea22af97b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/horace...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 9, 16, 24, 41, 508290, tzinfo=tzutc()), u'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', u'msg_type': u'execute_request', u'session': u'B3ECAA1D41124E63939DAFD03B40550F', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['B3ECAA1D41124E63939DAFD03B40550F']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 9, 16, 24, 41, 508290, tzinfo=tzutc()), u'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', u'msg_type': u'execute_request', u'session': u'B3ECAA1D41124E63939DAFD03B40550F', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['B3ECAA1D41124E63939DAFD03B40550F'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 9, 16, 24, 41, 508290, tzinfo=tzutc()), u'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', u'msg_type': u'execute_request', u'session': u'B3ECAA1D41124E63939DAFD03B40550F', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-14-c604360bea6a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7fea1ba19690, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fe9cbca2530, file \"<ipython-input-14-c604360bea6a>\", line 4>\n        result = <ExecutionResult object at 7fea1ba19690, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fe9cbca2530, file \"<ipython-input-14-c604360bea6a>\", line 4>, result=<ExecutionResult object at 7fea1ba19690, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fe9cbca2530, file \"<ipython-input-14-c604360bea6a>\", line 4>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BMapModel': <module 'BMapModel' from 'BMapModel.pyc'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'In': ['', u\"get_ipython().magic(u'matplotlib inline')\\nimp...m sklearn.ensemble import RandomForestClassifier\", u\"get_ipython().system(u'ls -R ../data')\", u\"get_ipython().magic(u'ls ../data/RCV1-x/rcv1x_test.txt')\", u'data_dir = \"../data\"\\nmodel_dir = \"../.model6\"..._hat = klogn*ratio\\nL_hat = 100\\ntime = TicToc()', u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u\"joblib.dump(X_tr, os.path.join(data_path, 'X_t...os.path.join(data_path, 'Y_te.pkl'), compress=3)\", u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u'k = sorted([Y.sum() for Y in Y_tr], reverse=True)[int(X_tr.shape[0]*0.01)]\\nk', u'L_hat', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()'], 'KDTree': <type 'sklearn.neighbors.kd_tree.KDTree'>, 'L_hat': 100, 'L_hat_ratio': 0.5, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultiLabelBinarizer': <class 'sklearn.preprocessing.label.MultiLabelBinarizer'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BMapModel': <module 'BMapModel' from 'BMapModel.pyc'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'In': ['', u\"get_ipython().magic(u'matplotlib inline')\\nimp...m sklearn.ensemble import RandomForestClassifier\", u\"get_ipython().system(u'ls -R ../data')\", u\"get_ipython().magic(u'ls ../data/RCV1-x/rcv1x_test.txt')\", u'data_dir = \"../data\"\\nmodel_dir = \"../.model6\"..._hat = klogn*ratio\\nL_hat = 100\\ntime = TicToc()', u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u\"joblib.dump(X_tr, os.path.join(data_path, 'X_t...os.path.join(data_path, 'Y_te.pkl'), compress=3)\", u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u'k = sorted([Y.sum() for Y in Y_tr], reverse=True)[int(X_tr.shape[0]*0.01)]\\nk', u'L_hat', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()'], 'KDTree': <type 'sklearn.neighbors.kd_tree.KDTree'>, 'L_hat': 100, 'L_hat_ratio': 0.5, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultiLabelBinarizer': <class 'sklearn.preprocessing.label.MultiLabelBinarizer'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/datadrive/Multi-label/src/<ipython-input-14-c604360bea6a> in <module>()\n      1 \n      2 \n      3 from sklearn.ensemble import RandomForestClassifier\n----> 4 clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=1)\n      5 time.tic()\n      6 clf.fit(X_tr, Z_tr)\n      7 time.toc()\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 99\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon Oct  9 18:09:02 2017\nPID: 3401               Python 2.7.13: /home/horacehxw/anaconda2/bin/python\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), None, 90, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), None, 90, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=None, tree_idx=90, n_trees=100, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1923688040, splitter='best')>\n        X = <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>\n        y = array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  0.,  1., ...,  1.,  2.,  2.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=array([ 1.,  0.,  1., ...,  1.,  2.,  2.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=array([ 1.,  0.,  1., ...,  1.,  2.,  2.]), check_input=False, X_idx_sorted=None)\n    345                                            min_weight_leaf,\n    346                                            max_depth,\n    347                                            max_leaf_nodes,\n    348                                            self.min_impurity_split)\n    349 \n--> 350         builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n        builder.build = <built-in method build of sklearn.tree._tree.DepthFirstTreeBuilder object>\n        self.tree_ = <sklearn.tree._tree.Tree object>\n        X = <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>\n        y = array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]])\n        sample_weight = array([ 1.,  0.,  1., ...,  1.,  2.,  2.])\n        X_idx_sorted = None\n    351 \n    352         if self.n_outputs_ == 1:\n    353             self.n_classes_ = self.n_classes_[0]\n    354             self.classes_ = self.classes_[0]\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/_tree.so in sklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn/tree/_tree.c:5002)()\n    137 \n    138 \n    139 \n    140 \n    141 \n--> 142 \n    143 \n    144 \n    145 \n    146 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/_tree.so in sklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn/tree/_tree.c:4829)()\n    264 \n    265 \n    266 \n    267 \n    268 \n--> 269 \n    270 \n    271 \n    272 \n    273 \n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c604360bea6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7fea22af97b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/horace...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7fea22af97b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/horace...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 9, 16, 24, 41, 508290, tzinfo=tzutc()), u'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', u'msg_type': u'execute_request', u'session': u'B3ECAA1D41124E63939DAFD03B40550F', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['B3ECAA1D41124E63939DAFD03B40550F']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 9, 16, 24, 41, 508290, tzinfo=tzutc()), u'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', u'msg_type': u'execute_request', u'session': u'B3ECAA1D41124E63939DAFD03B40550F', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['B3ECAA1D41124E63939DAFD03B40550F'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 9, 16, 24, 41, 508290, tzinfo=tzutc()), u'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', u'msg_type': u'execute_request', u'session': u'B3ECAA1D41124E63939DAFD03B40550F', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5738BAFD36504FB8BF6BA72AFF6CCDC5', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-14-c604360bea6a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7fea1ba19690, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fe9cbca2530, file \"<ipython-input-14-c604360bea6a>\", line 4>\n        result = <ExecutionResult object at 7fea1ba19690, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fe9cbca2530, file \"<ipython-input-14-c604360bea6a>\", line 4>, result=<ExecutionResult object at 7fea1ba19690, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fe9cbca2530, file \"<ipython-input-14-c604360bea6a>\", line 4>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BMapModel': <module 'BMapModel' from 'BMapModel.pyc'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'In': ['', u\"get_ipython().magic(u'matplotlib inline')\\nimp...m sklearn.ensemble import RandomForestClassifier\", u\"get_ipython().system(u'ls -R ../data')\", u\"get_ipython().magic(u'ls ../data/RCV1-x/rcv1x_test.txt')\", u'data_dir = \"../data\"\\nmodel_dir = \"../.model6\"..._hat = klogn*ratio\\nL_hat = 100\\ntime = TicToc()', u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u\"joblib.dump(X_tr, os.path.join(data_path, 'X_t...os.path.join(data_path, 'Y_te.pkl'), compress=3)\", u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u'k = sorted([Y.sum() for Y in Y_tr], reverse=True)[int(X_tr.shape[0]*0.01)]\\nk', u'L_hat', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()'], 'KDTree': <type 'sklearn.neighbors.kd_tree.KDTree'>, 'L_hat': 100, 'L_hat_ratio': 0.5, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultiLabelBinarizer': <class 'sklearn.preprocessing.label.MultiLabelBinarizer'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BMapModel': <module 'BMapModel' from 'BMapModel.pyc'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'In': ['', u\"get_ipython().magic(u'matplotlib inline')\\nimp...m sklearn.ensemble import RandomForestClassifier\", u\"get_ipython().system(u'ls -R ../data')\", u\"get_ipython().magic(u'ls ../data/RCV1-x/rcv1x_test.txt')\", u'data_dir = \"../data\"\\nmodel_dir = \"../.model6\"..._hat = klogn*ratio\\nL_hat = 100\\ntime = TicToc()', u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u\"joblib.dump(X_tr, os.path.join(data_path, 'X_t...os.path.join(data_path, 'Y_te.pkl'), compress=3)\", u\"X_tr = joblib.load(os.path.join(data_path, 'X_...joblib.load(os.path.join(data_path, 'Y_te.pkl'))\", u'X_tr.shape, X_te.shape', u'k = sorted([Y.sum() for Y in Y_tr], reverse=True)[int(X_tr.shape[0]*0.01)]\\nk', u'L_hat', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'Z_tr = util.map_2_z(Y_tr, L_hat)', u'from sklearn.ensemble import RandomForestClass...=1)\\ntime.tic()\\nclf.fit(X_tr, Z_tr)\\ntime.toc()'], 'KDTree': <type 'sklearn.neighbors.kd_tree.KDTree'>, 'L_hat': 100, 'L_hat_ratio': 0.5, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultiLabelBinarizer': <class 'sklearn.preprocessing.label.MultiLabelBinarizer'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/datadrive/Multi-label/src/<ipython-input-14-c604360bea6a> in <module>()\n      1 \n      2 \n      3 from sklearn.ensemble import RandomForestClassifier\n----> 4 clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=1)\n      5 time.tic()\n      6 clf.fit(X_tr, Z_tr)\n      7 time.toc()\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 99\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon Oct  9 18:09:02 2017\nPID: 3401               Python 2.7.13: /home/horacehxw/anaconda2/bin/python\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), None, 90, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), None, 90, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...state=1,\n            verbose=0, warm_start=False), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=None, tree_idx=90, n_trees=100, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1923688040, splitter='best')>\n        X = <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>\n        y = array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  0.,  1., ...,  1.,  2.,  2.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=array([ 1.,  0.,  1., ...,  1.,  2.,  2.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1923688040, splitter='best'), X=<623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>, y=array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]]), sample_weight=array([ 1.,  0.,  1., ...,  1.,  2.,  2.]), check_input=False, X_idx_sorted=None)\n    345                                            min_weight_leaf,\n    346                                            max_depth,\n    347                                            max_leaf_nodes,\n    348                                            self.min_impurity_split)\n    349 \n--> 350         builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n        builder.build = <built-in method build of sklearn.tree._tree.DepthFirstTreeBuilder object>\n        self.tree_ = <sklearn.tree._tree.Tree object>\n        X = <623847x42315 sparse matrix of type '<type 'nump...ored elements in Compressed Sparse Column format>\n        y = array([[ 0.,  0.,  0., ...,  0.,  1.,  1.],\n    ...1.],\n       [ 1.,  1.,  0., ...,  0.,  1.,  0.]])\n        sample_weight = array([ 1.,  0.,  1., ...,  1.,  2.,  2.])\n        X_idx_sorted = None\n    351 \n    352         if self.n_outputs_ == 1:\n    353             self.n_classes_ = self.n_classes_[0]\n    354             self.classes_ = self.classes_[0]\n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/_tree.so in sklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn/tree/_tree.c:5002)()\n    137 \n    138 \n    139 \n    140 \n    141 \n--> 142 \n    143 \n    144 \n    145 \n    146 \n\n...........................................................................\n/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/tree/_tree.so in sklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn/tree/_tree.c:4829)()\n    264 \n    265 \n    266 \n    267 \n    268 \n--> 269 \n    270 \n    271 \n    272 \n    273 \n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=1)\n",
    "time.tic()\n",
    "clf.fit(X_tr, Z_tr)\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf, os.path.join(model_path , 'label0.pkl'), compress=3)# only one classifiers, name for convention#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.2 Store the lower degree space info for kNN\n",
    "\n",
    "We use opensource faiss library from FAIR to speedup the ANN(Approximate Nearest Neighbor) search.\n",
    "\n",
    "When dimension and data size is relatively small, we use the brute force kNN search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# faiss brute force search\n",
    "nn_index = faiss.index_factory(Z_tr.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "nn_index.add(Z_tr.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```Python\n",
    "# index created by index factory\n",
    "nn_index = faiss.index_factory(Z_tr.shape[1], \"IVF100,Flat\", faiss.METRIC_L2) # need train\n",
    "nn_index.train(Z_tr.astype('float32'))\n",
    "nn_index.add(Z_tr.astype('float32'))\n",
    "\n",
    "print nn_index.nlist # number of clusters, only INF has this\n",
    "nn_index.nprobe = 1 # number of clusters to search through, only INF has this, need to be validate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Prediction and Validation\n",
    "\n",
    "test by RandomForest.predict and predict_prob to generate z_pred and then ues kNN to find y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "EOF: reading array data, expected 262144 bytes got 29797",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2a595ddc4380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, index=nn_index, \n\u001b[0;32m----> 2\u001b[0;31m                                Y_tr=Y_tr, model_path=model_path)\n\u001b[0m",
      "\u001b[0;32m/datadrive/Multi-label/src/BMapModel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, L, L_hat, Y_tr, index, model_path, Mat, num_core)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_core\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datadrive/Multi-label/src/BMapModel.pyc\u001b[0m in \u001b[0;36mload_clf\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# load the binary classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'label{}.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArrayWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;31m# Be careful to register our new method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     data = _read_bytes(unpickler.file_handle,\n\u001b[0;32m--> 134\u001b[0;31m                                        read_size, \"array data\")\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mread_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                         unpickler.np.frombuffer(data, dtype=self.dtype,\n",
      "\u001b[0;32m/home/horacehxw/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle_utils.pyc\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EOF: reading %s, expected %d bytes got %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: EOF: reading array data, expected 262144 bytes got 29797"
     ]
    }
   ],
   "source": [
    "model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, index=nn_index, \n",
    "                               Y_tr=Y_tr, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred = model.predict_y(X_te, vote=100, classifier='RandomForest') # 1 nearest neighbor\n",
    "time.toc()\n",
    "util.precision_at_k(Y_te, Y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_prob = model.predict_prob_z(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred = model.predict_y(X_te,  vote=100, classifier='RandomForest', predict_prob=True) # 1 nearest neighbor\n",
    "time.toc()\n",
    "util.precision_at_k(Y_te, Y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate_voter(voter, use_prob):\n",
    "    Y_pred = model.predict_y(X_te, vote=voter, classifier='RandomForest', \n",
    "                             predict_prob=use_prob)\n",
    "    return (util.precision_at_k(Y_te, Y_pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_at_k_votes_prob = Parallel(n_jobs=num_core)\\\n",
    "                    (delayed(validate_voter)(voter, True) for voter in range(1, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_at_k_votes = Parallel(n_jobs=num_core)\\\n",
    "                    (delayed(validate_voter)(voter, False) for voter in range(1, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,150), p_at_k_votes_prob, label='pred_prob')\n",
    "plt.plot(range(1,150), p_at_k_votes, label='pred')\n",
    "plt.xlabel('number of voters in kNN')\n",
    "plt.ylabel('p@1 score')\n",
    "plt.title('L_hat={}, RandomForest predict_prob, {}'.format(L_hat, train_filename))\n",
    "plt.legend()\n",
    "top = np.argmax(p_at_k_votes)\n",
    "(p_at_k_votes[top], top), (np.max(p_at_k_votes_prob), np.argmax(p_at_k_votes_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3 optimize hyperparameter\n",
    "use  k fold cross validation to optimize over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# validate the result with different L_hat under the same model\n",
    "def validate(L_hat, pk=1, vote=20, use_prob=False): # simple forkable parallel for loop body\n",
    "    from util import map_2_z\n",
    "    from util import precision_at_k\n",
    "\n",
    "   # for train_index, test_index in k_fold.split(X_tr):\n",
    "    x_train = X_tr\n",
    "    y_train = Y_tr\n",
    "    x_test = X_te\n",
    "    y_test = Y_te\n",
    "\n",
    "    # map and create kNN index\n",
    "    z_train = map_2_z(y_train, L_hat)\n",
    "    # faiss brute force search\n",
    "    knn_index = faiss.index_factory(z_train.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "    knn_index.add(z_train.astype('float32'))\n",
    "    #train clf\n",
    "    clf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "    clf.fit(x_train, z_train)\n",
    "    # construct model\n",
    "    model = BMapModel.BM_Predictor(Y_tr.shape[1], 1, index=knn_index, Y_tr=y_train)\n",
    "    model.clfs.append(clf)\n",
    "    #predict and calculate p@k score\n",
    "    y_pred = model.predict_y(x_test, vote=vote, weighted=True, classifier='RandomForest', predict_prob=use_prob)\n",
    "    # precision@pk\n",
    "    return precision_at_k(y_test, y_pred, k=pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize L_hat's value on the metric precision@k\n",
    "pk=1\n",
    "vote=100\n",
    "L_hat_range = range(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_hat_score = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(validate)(L_hat, pk, vote) for L_hat in L_hat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hat_score_prob = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(validate)(L_hat, pk, vote, True) for L_hat in L_hat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_down, = plt.plot(range(1,200), L_hat_score, label='random forest performance')\n",
    "plt.xlabel('L_hat')\n",
    "plt.ylabel('precision@{}'.format(pk))\n",
    "plt.title('Delicious validation on L_hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4 Bit Flip Probability\n",
    "the classifiers predict $\\hat z$ can be viewed as transmiting z from a BSC channel with some bit flip probability, this is actually representing the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hat, X_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_channel(X_te, Y_te):\n",
    "    z_te = util.map_2_z(Y_te, L_hat)\n",
    "    # use the classifers to predict z_hat\n",
    "    model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, model_path=model_path)\n",
    "    z_pred = model.predict_z(X_te)\n",
    "    \n",
    "    hamming = []\n",
    "    for i in range(z_te.shape[0]):\n",
    "        hamming.append((z_pred[i]!=z_te[i]).sum())\n",
    "    return np.array(hamming) / float(z_te.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error = validate_channel(X_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(test_error, bins=20)\n",
    "plt.xlabel('error rate between z_te and z_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('Delicious: distribution of bit_flip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_error = validate_channel(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(training_error, bins=20)\n",
    "plt.xlabel('error rate between z_train and z_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('{}: distribution of training error'.format(train_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.5 Train and test model directly on the X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir_mirror = model_dir+\"_origin\"\n",
    "model_path_mirror = model_dir_mirror+path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)\n",
    "time.tic()\n",
    "classifier.fit(X=X_tr, y=Y_tr)\n",
    "time.toc()\n",
    "#joblib.dump(classifier, os.path.join(model_path_mirror , 'RandomForestClassifier.pkl'))# only one classifiers, name for convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier = joblib.load(os.path.join(model_path_mirror , 'RandomForestClassifier.pkl'))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "y_pred = classifier.predict(X_te)\n",
    "time.toc('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamming = []\n",
    "for i in range(y_pred.shape[0]):\n",
    "    hamming.append((y_pred[i]!=Y_te[i]).sum())\n",
    "hamming = np.array(hamming) / float(Y_te.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(hamming)\n",
    "plt.xlabel('error_rate')\n",
    "plt.ylabel('density')\n",
    "plt.title('test error rate distribution, {}, Randomforest, mean={}'.format(train_filename, hamming.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "y_pred_prob = classifier.predict_proba(X_te) #for every label there's a 2D (sample, output(2)) probability\n",
    "time.toc('predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = np.ascontiguousarray(np.array([prob[:, 1] for prob in y_pred_prob]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the precision@k of RandomForest.predict_prob training directly on X_tr and Y_tr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, y_prob, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "precit_prob + kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_tr_index = faiss.index_factory(Y_tr.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "Y_tr_index.add(Y_tr.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist, ind = Y_tr_index.search(y_prob.astype('float32'), 1)\n",
    "y_prob_vote = np.array([np.sum([Y_tr[ind[i][j]] for j in range(len(ind[i]))], axis=0) for i in range(len(ind))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, y_prob_vote, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_bits(message, p0, p1):\n",
    "    '''\n",
    "    randomly flip every \"1\" w/ prob p1, and every \"0\" w/ p0\n",
    "    '''\n",
    "    def flip(bit):\n",
    "        if bit==1 and np.random.rand()<p1:\n",
    "            bit = 0\n",
    "        if bit==0 and np.random.rand()<p0:\n",
    "            bit=1\n",
    "        return bit\n",
    "    np.random.seed(0)\n",
    "    return np.apply_along_axis(lambda bits: np.array([flip(bit) for bit in bits]), 0, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flip_bits(np.array([[1,0,1],[0,1,1]]), 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
