{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M6ï¼š Binary map + Random Forest + kNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load GPU Faiss: No module named swigfaiss_gpu\n",
      "Faiss falling back to CPU-only.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import os\n",
    "import data_util\n",
    "import BMapModel\n",
    "#from data_util import DataPoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import faiss\n",
    "import util\n",
    "import scipy\n",
    "# import joblib # version incompatibel with sklearn's joblib and can't load the previous model\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib # store classifiers\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # convert y to {0,1}^L\n",
    "from sklearn.preprocessing import StandardScaler # normalize features \n",
    "from sklearn.feature_extraction import DictVectorizer # extract feature vector to x\n",
    "from numpy.random import normal # generate transforming matrix\n",
    "from sklearn.neighbors import KDTree #KDTree for fast kNN search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from joblib import Parallel, delayed # Multitread\n",
    "from pytictoc import TicToc\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data:\r\n",
      "AmazonCat  Delicious\t   Eurlex     RCV1-x\t       Wiki10\r\n",
      "Bibtex\t   DeliciousLarge  Mediamill  README_Datasets  XMLDatasetRead\r\n",
      "\r\n",
      "../data/AmazonCat:\r\n",
      "amazonCat_test.txt  amazonCat_train.txt  X_te.npz  X_tr.npz  Y_te.npz  Y_tr.npz\r\n",
      "\r\n",
      "../data/Bibtex:\r\n",
      "Bibtex_data.txt  bibtex_trSplit.txt  bibtex_tstSplit.txt\r\n",
      "\r\n",
      "../data/Delicious:\r\n",
      "Delicious_data.txt     delicious_tstSplit.txt  X_tr.pkl  Y_tr.pkl\r\n",
      "delicious_trSplit.txt  X_te.pkl\t\t       Y_te.pkl\r\n",
      "\r\n",
      "../data/DeliciousLarge:\r\n",
      "deliciousLarge_test.txt   X_te.npz  Y_te.npz\r\n",
      "deliciousLarge_train.txt  X_tr.npz  Y_tr.npz\r\n",
      "\r\n",
      "../data/Eurlex:\r\n",
      "eurlex_test.txt  eurlex_train.txt\r\n",
      "\r\n",
      "../data/Mediamill:\r\n",
      "Mediamill_data.txt  mediamill_trSplit.txt  mediamill_tstSplit.txt\r\n",
      "\r\n",
      "../data/RCV1-x:\r\n",
      "rcv1x_test.txt\trcv1x_train.txt  X_te.pkl  X_tr.pkl  Y_te.pkl  Y_tr.pkl\r\n",
      "\r\n",
      "../data/Wiki10:\r\n",
      "wiki10_test.txt  wiki10_train.txt  X_te.pkl  X_tr.pkl  Y_te.pkl  Y_tr.pkl\r\n",
      "\r\n",
      "../data/XMLDatasetRead:\r\n",
      "XMLDatasetRead\r\n",
      "\r\n",
      "../data/XMLDatasetRead/XMLDatasetRead:\r\n",
      "ReadData_Matlab  README_Datasets\r\n",
      "\r\n",
      "../data/XMLDatasetRead/XMLDatasetRead/ReadData_Matlab:\r\n",
      "make.m\tread_data.cpp  README.txt  write_data.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/Eurlex/eurlex_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "model_dir = \"../.model6\"\n",
    "train_filename = \"/Eurlex/eurlex_train.txt\"\n",
    "test_filename = \"/Eurlex/eurlex_train.txt\"\n",
    "#tr_split_file = \"/Delicious/delicious_trSplit.txt\"\n",
    "#te_split_file = \"/Delicious/delicious_tstSplit.txt\"\n",
    "\n",
    "path = os.path.dirname(train_filename)\n",
    "model_path = model_dir + path\n",
    "data_path = data_dir + path\n",
    "num_core = -1\n",
    "L_hat_ratio = 0.5 # useful when calculate L_hat = klogn*ratio\n",
    "L_hat = 100\n",
    "time = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_point=15539, num_label=3993, num_feature=5000\n"
     ]
    }
   ],
   "source": [
    "tr_data, num_point, num_feature, num_label = data_util.read_file(data_dir+train_filename)\n",
    "te_data, _, _, _ = data_util.read_file(data_dir+test_filename)\n",
    "#tr_split = data_util.split_data(data=tr_data, split_file=data_dir+tr_split_file)\n",
    "#te_split = data_util.split_data(data=tr_data, split_file=data_dir+te_split_file)\n",
    "print(\"num_point={}, num_label={}, num_feature={}\".format(num_point, num_label, num_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessing 9.340870 seconds.\n"
     ]
    }
   ],
   "source": [
    "time.tic()\n",
    "X_tr, Y_tr, X_te, Y_te = data_util.data_transform(tr_data, te_data, num_label)\n",
    "time.toc('data preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15539, 5000), (15539, 5000), (15539, 3993), (15539, 3993))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_npz(name, x):\n",
    "    scipy.sparse.save_npz(os.path.join(data_path, '{}.npz'.format(name)), x)\n",
    "def load_npz(x):\n",
    "    return scipy.sparse.load_npz(os.path.join(data_path, '{}.npz'.format(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, x in zip(['X_tr', 'X_te', 'Y_tr', 'Y_te'], [X_tr, X_te, Y_tr, Y_te]):\n",
    "    save_npz(name, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, x in zip(['X_tr', 'X_te', 'Y_tr', 'Y_te'], [X_tr, X_te, Y_tr, Y_te]):\n",
    "    x = load_npz(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15539, 5000), (15539, 5000), (15539, 3993), (15539, 3993))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: map to $\\hat L$ space and kNN search index\n",
    "\n",
    "We apply $$\\hat L = k \\log L$$ where $k$ indicates the sparsity of each label vector $y_i = \\{0,1\\}^L$. By default we choose k to be the 99.9% maximum sparsity to avoid extreme cases.\n",
    "\n",
    "The data in \"Eurlex\" contains $L = 5000$ labels, we are trying to map it into $\\hat L = 200$ space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_k = Y_tr.getnnz() / float(Y_tr.shape[0])\n",
    "avg_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sorted([Y_tr[i, :].getnnz() for i in range(Y_tr.shape[0])], reverse=True)\\\n",
    "    [int(X_tr.shape[0]*0.01)]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_hat = int(math.ceil(avg_k * math.log(Y_tr.shape[1], 2) * L_hat_ratio))\n",
    "L_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Z_tr = util.map_2_z(Y_tr, L_hat)\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Z_tr == 1).sum() / float(Z_tr.shape[0] * Z_tr.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Model\n",
    "\n",
    "#### 2.1 train binary classifiers on each bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=1)\n",
    "time.tic()\n",
    "clf.fit(X_tr, Z_tr)\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf, os.path.join(model_path , 'label0.pkl'), compress=3)# only one classifiers, name for convention#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load(os.path.join(model_path , 'label0.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.2 Store the lower degree space info for kNN\n",
    "\n",
    "We use opensource faiss library from FAIR to speedup the ANN(Approximate Nearest Neighbor) search.\n",
    "\n",
    "When dimension and data size is relatively small, we use the brute force kNN search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# faiss brute force search\n",
    "nn_index = faiss.index_factory(Z_tr.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "time.tic()\n",
    "nn_index.add(Z_tr.astype('float32'))\n",
    "time.toc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```Python\n",
    "# index created by index factory, Approximate kNN search\n",
    "nn_index = faiss.index_factory(Z_tr.shape[1], \"IVF100,Flat\", faiss.METRIC_L2) # need train\n",
    "nn_index.train(Z_tr.astype('float32'))\n",
    "nn_index.add(Z_tr.astype('float32'))\n",
    "print \"nlist = {}\".format(nn_index.nlist) # number of clusters, only INF has this\n",
    "print \"nprobe = {}\".format(nn_index.nprobe)\n",
    "nn_index.nprobe = 1 # number of clusters to search through, only INF has this, need to be validate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Prediction and Validation\n",
    "\n",
    "test by RandomForest.predict and predict_prob to generate z_pred and then ues kNN to find y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, index=nn_index, \n",
    "                               Y_tr=Y_tr, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred = model.predict_y(X_te, vote=100, classifier='RandomForest') # 1 nearest neighbor\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred_p = model.predict_y(X_te,  vote=100, classifier='RandomForest', predict_prob=True) # 1 nearest neighbor\n",
    "time.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    print \"precesion at {} for classification:\\t {}\\n\".format(i, util.precision_at_k(Y_te, Y_pred, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    print \"precesion at {} for probability predict:\\t {}\\n\"\\\n",
    "        .format(i, util.precision_at_k(Y_te, Y_pred_p, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "z_prob = model.predict_prob_z(X_te)\n",
    "time.toc('predict prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "dist, ind = nn_index.search(z_prob.astype('float32'), 100)\n",
    "#time.toc('Approximate-kNN search with probe={}'.format(model.index.nprobe))\n",
    "time.toc('kNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "Y_pred_t = np.array([np.sum([Y_tr[ind[i][j]] for j in range(len(ind[i]))], axis=0) for i in range(len(ind))])\n",
    "time.toc('weighted votes on kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result (vote = 100, kNN = brute force)\n",
    "\n",
    "|DataSet        |precision@k| RF Classification | RF predict prob | DiSMEC | SLEEK | FastXML\n",
    "|----| \n",
    "|RCV1-2k        |p@1        | 80.6              | 80.9            | *      | *     | * \n",
    "|               |p@2        | 68.0              | 68.2            | *      | *     | * \n",
    "|               |p@3        | 63.9              | 64.1            | *      | *     | *  \n",
    "|Wiki10-31k     |p@1        | 80.80             | 80.81           | 85.20  | **85.88** | 83.03 \n",
    "|               |p@2        | 62.74             | 64.65           | **74.60**  | 72.98 | 67.74  \n",
    "|               |p@3        | 54.91             | 56.54           | **65.90**  | 62.70 | 57.76 \n",
    "|Delicious-200k |p@1        | 80.80             | 80.81           | 45.50  | 47.85 | 43.07\n",
    "|               |p@2        | 62.74             | 64.65           | 38.70  | 42.21 | 38.66  \n",
    "|               |p@3        | 54.91             | 56.54           | 35.50  | 39.43 | 36.19\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate_voter(voter, use_prob):\n",
    "    Y_pred = model.predict_y(X_te, vote=voter, classifier='RandomForest', \n",
    "                             predict_prob=use_prob)\n",
    "    return (util.precision_at_k(Y_te, Y_pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_at_k_votes_prob = Parallel(n_jobs=num_core)\\\n",
    "                    (delayed(validate_voter)(voter, True) for voter in range(1, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_at_k_votes = Parallel(n_jobs=num_core)\\\n",
    "                    (delayed(validate_voter)(voter, False) for voter in range(1, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,150), p_at_k_votes_prob, label='pred_prob')\n",
    "plt.plot(range(1,150), p_at_k_votes, label='pred')\n",
    "plt.xlabel('number of voters in kNN')\n",
    "plt.ylabel('p@1 score')\n",
    "plt.title('L_hat={}, RandomForest predict_prob, {}'.format(L_hat, train_filename))\n",
    "plt.legend()\n",
    "top = np.argmax(p_at_k_votes)\n",
    "(p_at_k_votes[top], top), (np.max(p_at_k_votes_prob), np.argmax(p_at_k_votes_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3 optimize hyperparameter\n",
    "use  k fold cross validation to optimize over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# validate the result with different L_hat under the same model\n",
    "def validate(L_hat, pk=1, vote=20, use_prob=False): # simple forkable parallel for loop body\n",
    "    from util import map_2_z\n",
    "    from util import precision_at_k\n",
    "\n",
    "   # for train_index, test_index in k_fold.split(X_tr):\n",
    "    x_train = X_tr\n",
    "    y_train = Y_tr\n",
    "    x_test = X_te\n",
    "    y_test = Y_te\n",
    "\n",
    "    # map and create kNN index\n",
    "    z_train = map_2_z(y_train, L_hat)\n",
    "    # faiss brute force search\n",
    "    knn_index = faiss.index_factory(z_train.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "    knn_index.add(z_train.astype('float32'))\n",
    "    #train clf\n",
    "    clf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "    clf.fit(x_train, z_train)\n",
    "    # construct model\n",
    "    model = BMapModel.BM_Predictor(Y_tr.shape[1], 1, index=knn_index, Y_tr=y_train)\n",
    "    model.clfs.append(clf)\n",
    "    #predict and calculate p@k score\n",
    "    y_pred = model.predict_y(x_test, vote=vote, weighted=True, classifier='RandomForest', predict_prob=use_prob)\n",
    "    # precision@pk\n",
    "    return precision_at_k(y_test, y_pred, k=pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize L_hat's value on the metric precision@k\n",
    "pk=1\n",
    "vote=100\n",
    "L_hat_range = range(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_hat_score = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(validate)(L_hat, pk, vote) for L_hat in L_hat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hat_score_prob = Parallel(n_jobs=num_core)\\\n",
    "    (delayed(validate)(L_hat, pk, vote, True) for L_hat in L_hat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_down, = plt.plot(range(1,200), L_hat_score, label='random forest performance')\n",
    "plt.xlabel('L_hat')\n",
    "plt.ylabel('precision@{}'.format(pk))\n",
    "plt.title('Delicious validation on L_hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4 Bit Flip Probability\n",
    "the classifiers predict $\\hat z$ can be viewed as transmiting z from a BSC channel with some bit flip probability, this is actually representing the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hat, X_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_channel(X_te, Y_te):\n",
    "    z_te = util.map_2_z(Y_te, L_hat)\n",
    "    # use the classifers to predict z_hat\n",
    "    model = BMapModel.BM_Predictor(Y_tr.shape[1], L_hat=1, model_path=model_path,)\n",
    "    z_pred = model.predict_z(X_te)\n",
    "    \n",
    "    hamming = []\n",
    "    for i in range(z_te.shape[0]):\n",
    "        hamming.append((z_pred[i]!=z_te[i]).sum())\n",
    "    return np.array(hamming) / float(z_te.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error = validate_channel(X_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(test_error, bins=20)\n",
    "plt.xlabel('error rate between z_te and z_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('Delicious: distribution of bit_flip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_error = validate_channel(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(training_error, bins=20)\n",
    "plt.xlabel('error rate between z_train and z_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('{}: distribution of training error'.format(train_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.5 Train and test model directly on the X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir_mirror = model_dir+\"_origin\"\n",
    "model_path_mirror = model_dir_mirror+path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)\n",
    "time.tic()\n",
    "classifier.fit(X=X_tr, y=Y_tr)\n",
    "time.toc()\n",
    "#joblib.dump(classifier, os.path.join(model_path_mirror , 'RandomForestClassifier.pkl'))# only one classifiers, name for convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier = joblib.load(os.path.join(model_path_mirror , 'RandomForestClassifier.pkl'))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "y_pred = classifier.predict(X_te)\n",
    "time.toc('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamming = []\n",
    "for i in range(y_pred.shape[0]):\n",
    "    hamming.append((y_pred[i]!=Y_te[i]).sum())\n",
    "hamming = np.array(hamming) / float(Y_te.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(hamming)\n",
    "plt.xlabel('error_rate')\n",
    "plt.ylabel('density')\n",
    "plt.title('test error rate distribution, {}, Randomforest, mean={}'.format(train_filename, hamming.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.tic()\n",
    "y_pred_prob = classifier.predict_proba(X_te) #for every label there's a 2D (sample, output(2)) probability\n",
    "time.toc('predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = np.ascontiguousarray(np.array([prob[:, 1] for prob in y_pred_prob]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the precision@k of RandomForest.predict_prob training directly on X_tr and Y_tr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, y_prob, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "precit_prob + kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_tr_index = faiss.index_factory(Y_tr.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "Y_tr_index.add(Y_tr.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist, ind = Y_tr_index.search(y_prob.astype('float32'), 1)\n",
    "y_prob_vote = np.array([np.sum([Y_tr[ind[i][j]] for j in range(len(ind[i]))], axis=0) for i in range(len(ind))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.precision_at_k(Y_te, y_prob_vote, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_bits(message, p0, p1):\n",
    "    '''\n",
    "    randomly flip every \"1\" w/ prob p1, and every \"0\" w/ p0\n",
    "    '''\n",
    "    def flip(bit):\n",
    "        if bit==1 and np.random.rand()<p1:\n",
    "            bit = 0\n",
    "        if bit==0 and np.random.rand()<p0:\n",
    "            bit=1\n",
    "        return bit\n",
    "    np.random.seed(0)\n",
    "    return np.apply_along_axis(lambda bits: np.array([flip(bit) for bit in bits]), 0, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flip_bits(np.array([[1,0,1],[0,1,1]]), 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
