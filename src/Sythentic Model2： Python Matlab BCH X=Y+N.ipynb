{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sythetic Multilabel Classification\n",
    "\n",
    "## Data Generation\n",
    " y <== L dimension one-hot vector, each entry represent a label\n",
    " \n",
    " X <== y + N(0, $\\sigma$)\n",
    " \n",
    " ## Train Process\n",
    " \n",
    "* y $\\in [0,1]^L$\n",
    " \n",
    "* $\\bar y = sign(M\\cdot y) \\in [0,1]^{\\bar L}$, where M is a iid gaussian entry embedding matrix (store $\\bar Y$ into local files for Matlab)\n",
    " \n",
    "* $\\tilde y = \\textbf{BCHencode}(\\bar y) \\in [0,1]^{\\tilde L}$ (need to use Matlab)\n",
    " \n",
    "* Train multi-label random forest on $X, \\tilde y$ \n",
    "\n",
    "**Notice**: for the BCH code, we choose the message length to be 67, codeword length to be 511, the error correction bit is 87. \n",
    "\n",
    "The error correction rate is 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement general One vs All classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "time = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import OvsA\n",
    "clf = OvsA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import binomial\n",
    "from numpy.random import normal\n",
    "from numpy.random import randint\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "SPARSE = 0.05 # sparsity of label vectors\n",
    "SIGMA = 0. # standard diveation of noise\n",
    "L = 500 # feature and label dimension\n",
    "N = 10000 # number of data points\n",
    "voter = 30 # number of nearest neighbors to search\n",
    "\n",
    "L_bar = 45 # embedding dimension, also the message length for BCH code\n",
    "L_tilde = 255 # codeword length for BCH encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "y = binomial(1, SPARSE, size=(N, L)) # iid Bernoulli entries\n",
    "X = y + normal(loc=0, scale=SIGMA, size=(N, L))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load GPU Faiss: No module named swigfaiss_gpu\n",
      "Faiss falling back to CPU-only.\n"
     ]
    }
   ],
   "source": [
    "# Source encode + KNN searcher\n",
    "M = normal(size=[L, L_bar])\n",
    "y_train_bar = (np.sign(y_train.dot(M))+1)/2\n",
    "y_test_bar = (np.sign(y_test.dot(M)) + 1) / 2\n",
    "import faiss\n",
    "nn_index = faiss.index_factory(y_train_bar.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "nn_index.add(y_train_bar.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save y_bar to matlab file\n",
    "from scipy.io import savemat, loadmat\n",
    "savemat(file_name=\"../.temp/train/y_bar\", mdict={'y_bars':[y_train_bar],\n",
    "                                                 'y_test':y_test_bar,\n",
    "                                                 'L_tilde':L_tilde\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Using **Matlab** to encode $\\bar y$ into $\\tilde y$ ...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train_tilde[:, :45] == y_train_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the y_tilde file generated by matlab\n",
    "from scipy.io import savemat, loadmat\n",
    "y_tildes = loadmat(\"../.temp/train/y_tilde\")['y_tildes'].astype('float')\n",
    "y_train_tilde = y_tildes[0]\n",
    "y_test_tilde = loadmat(\"../.temp/train/y_tilde\")['y_test_tilde'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "float(y_train_tilde.sum()) / (y_train_tilde.shape[0] * y_train_tilde.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the random forest multi-label classifier\n",
    "from pytictoc import TicToc\n",
    "time = TicToc()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(n_jobs=-1, n_estimators=48)\n",
    "from sklearn.svm import SVC\n",
    "#clf = SVC()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#clf = LogisticRegression()\n",
    "clf = OvsA(LogisticRegression)\n",
    "\n",
    "time.tic()\n",
    "clf.fit(X_train, y_train_tilde)\n",
    "time.toc(\"train classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the bit flip probability for y_bar\n",
    "clf_ = OvsA(LogisticRegression)\n",
    "clf_.fit(X_train, y_train_bar)\n",
    "y_predict_bar = clf_.predict(X_test)\n",
    "1 - (y_predict_bar == y_test_bar).sum() / float(y_predict_bar.shape[0] * y_predict_bar.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tilde_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tilde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tilde_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(y_test_tilde == y_tilde_hat).sum() / float(y_test_tilde.shape[0] * y_test_tilde.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "savemat(file_name=\"../.temp/test/y_tilde_hat\", \n",
    "        mdict={'y_tilde_hats':[y_tilde_hat],\n",
    "               'L_bar':L_bar\n",
    "              }\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tilde_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Using **Matlab** to decode $\\hat{\\tilde y}$ into $\\hat{\\bar y}$ ...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the y_tilde file generated by matlab\n",
    "from scipy.io import savemat, loadmat\n",
    "y_bar_hats = loadmat(\"../.temp/test/y_bar_hat.mat\")['y_bar_hats'].astype(int)\n",
    "y_bar_hat = y_bar_hats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use KNN searcher to recover the predicted y_hat\n",
    "dist, ind = nn_index.search(np.ascontiguousarray(y_bar_hat.astype('float32')), voter)\n",
    "y_hat = np.stack([\n",
    "    np.sum(np.array([\n",
    "        y_train[indij].astype('float32')/float(distij**2 + 0.01) for indij, distij in zip(indi, disti)\n",
    "    ]), axis=0)\n",
    "    for indi, disti in zip(ind, dist)\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_at_k(truth, vote, k=1):\n",
    "    assert(truth.shape == vote.shape)\n",
    "    success = 0\n",
    "    for i in range(truth.shape[0]):\n",
    "        topk = np.argpartition(vote[i], -k)[-k:]\n",
    "        success += truth[i, topk].sum()\n",
    "    return success / ((float(truth.shape[0]))*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision_at_k(y_test, y_hat, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_tilde, y_tilde_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Results\n",
    "\n",
    "* random forest classifer for multi-label task\n",
    "\n",
    "$\\sigma$| p@1 | p@3 | p@5 \n",
    "  ---   | --- | --- | --- \n",
    "    0   | 0.126 | 0.107 | 0.099\n",
    "    0.1 | 0.112 | 0.091 | 0.085\n",
    "    0.4 | 0.063 | 0.061 | 0.059\n",
    "     \n",
    "* OvsA with logistic regression \n",
    "\n",
    "$\\sigma$| p@1 | p@3 | p@5 \n",
    "  ---   | --- | --- | --- \n",
    "    0   | 0.126 | 0.107 | 0.099\n",
    "    0.01 | 0.112 | 0.091 | 0.085\n",
    "    0.05 | 0.063 | 0.061 | 0.059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tilde_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
