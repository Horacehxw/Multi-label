{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sythetic Multilabel Classification\n",
    "\n",
    "## Data Generation\n",
    " y <== L dimension one-hot vector, each entry represent a label\n",
    " \n",
    " X <== y + N(0, $\\sigma$)\n",
    " \n",
    " ## Train Process\n",
    " \n",
    "* y $\\in [0,1]^L$\n",
    " \n",
    "* $\\bar y = sign(M\\cdot y) \\in [0,1]^{\\bar L}$, where M is a iid gaussian entry embedding matrix (store $\\bar Y$ into local files for Matlab)\n",
    " \n",
    "* $\\tilde y = \\textbf{BCHencode}(\\bar y) \\in [0,1]^{\\tilde L}$ (need to use Matlab)\n",
    " \n",
    "* Train multi-label random forest on $X, \\tilde y$ \n",
    "\n",
    "**Notice**: for the BCH code, we choose the message length to be 67, codeword length to be 511, the error correction bit is 87. \n",
    "\n",
    "The error correction rate is 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement general One vs All classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "time = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import OvsA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import Parallel, delayed\n",
    "def fit_bit(method, X, y):\n",
    "    return method().fit(X, y)\n",
    "\n",
    "def predict_bit(clf, X):\n",
    "    return clf.predict(X)\n",
    "\n",
    "class OvsA():\n",
    "    '''\n",
    "    use OvsA technic to predict one bit in y by a base classifier\n",
    "    '''\n",
    "    def __init__(self, method=LogisticRegression, n_jobs=-1):\n",
    "        '''\n",
    "        method: \n",
    "            the function to generate the base classifiers.\n",
    "        '''\n",
    "        self.method = method\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    def predict(self, X):\n",
    "        bits = Parallel(n_jobs=self.n_jobs)(delayed(predict_bit)(clf, X)\n",
    "                                           for clf in self.clfs)\n",
    "#         bits = [clf.predict(X) for clf in self.clfs]\n",
    "        return np.stack(bits, axis=1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clfs = Parallel(n_jobs=self.n_jobs)(delayed(fit_bit)(self.method, X, y[:,i]) \n",
    "                                     for i in range(y.shape[1]))\n",
    "#         self.clfs = [self.method().fit(X, y[:, i]) for i in range(y.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedClf():\n",
    "    '''\n",
    "    use two different multilabel classifier classifier for\n",
    "        X -> y[:, :x] and X -> y[:, x:]\n",
    "    '''\n",
    "    def __init__(self, clf1, clf2, seperate):\n",
    "        '''\n",
    "        input:\n",
    "            method1,2: \n",
    "                method that return a new classifier needed\n",
    "            sperate:\n",
    "                the part that seperates which classifier to use\n",
    "            n_jobs:\n",
    "                number of treads to use\n",
    "        '''\n",
    "        self.clf1 = clf1\n",
    "        self.clf2 = clf2\n",
    "        self.seperate = seperate\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y1 = self.clf1.predict(X)\n",
    "        y2 = self.clf2.predict(X)\n",
    "        return np.append(y1, y2, axis=1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clf1.fit(X, y[:, :self.seperate])\n",
    "        self.clf2.fit(X, y[:, self.seperate:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import binomial\n",
    "from numpy.random import normal\n",
    "from numpy.random import randint\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "SPARSE = 0.05 # sparsity of label vectors\n",
    "SIGMA = 0. # standard diveation of noise\n",
    "FLIP_RATE = 0.005 # probability that bits in y flipped in bits of X\n",
    "L = 500 # feature and label dimension\n",
    "N = 10000 # number of data points\n",
    "voter = 30 # number of nearest neighbors to search\n",
    "\n",
    "L_bar = 45 # embedding dimension, also the message length for BCH code\n",
    "L_tilde = 255 # codeword length for BCH encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "y = binomial(1, SPARSE, size=(N, L)) # iid Bernoulli entries\n",
    "#X = y + normal(loc=0, scale=SIGMA, size=(N, L))\n",
    "flip_bits = binomial(1, FLIP_RATE, size=(N, L))\n",
    "X = y^flip_bits\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load GPU Faiss: No module named swigfaiss_gpu\n",
      "Faiss falling back to CPU-only.\n"
     ]
    }
   ],
   "source": [
    "# Source encode + KNN searcher\n",
    "M = normal(size=[L, L_bar])\n",
    "y_train_bar = (np.sign(y_train.dot(M))+1)/2\n",
    "y_test_bar = (np.sign(y_test.dot(M)) + 1) / 2\n",
    "import faiss\n",
    "nn_index = faiss.index_factory(y_train_bar.shape[1], \"Flat\", faiss.METRIC_L2)   # build the index\n",
    "nn_index.add(y_train_bar.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save y_bar to matlab file\n",
    "from scipy.io import savemat, loadmat\n",
    "savemat(file_name=\"../.temp/train/y_bar\", mdict={'y_bars':[y_train_bar],\n",
    "                                                 'y_test':y_test_bar,\n",
    "                                                 'L_tilde':L_tilde\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 45)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Using **Matlab** to encode $\\bar y$ into $\\tilde y$ ...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the y_tilde file generated by matlab\n",
    "from scipy.io import savemat, loadmat\n",
    "y_tildes = loadmat(\"../.temp/train/y_tilde\")['y_tildes'].astype('float')\n",
    "y_train_tilde = y_tildes[0]\n",
    "y_test_tilde = loadmat(\"../.temp/train/y_tilde\")['y_test_tilde'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 255)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tilde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4986713491366696"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(y_train_tilde.sum()) / (y_train_tilde.shape[0] * y_train_tilde.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classifier 330.299255 seconds.\n"
     ]
    }
   ],
   "source": [
    "# train the random forest multi-label classifier\n",
    "from pytictoc import TicToc\n",
    "time = TicToc()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = OvsA(SVC)\n",
    "# clf = CombinedClf(OvsA(SVC), RandomForestClassifier(n_estimators=48, n_jobs=-1),\n",
    "#                   seperate = L_bar)\n",
    "clf = CombinedClf(OvsA(SVC), MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000),\n",
    "                  seperate = L_bar)\n",
    "\n",
    "time.tic()\n",
    "clf.fit(X_train, y_train_tilde)\n",
    "time.toc(\"train classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 99.326697 seconds.\n"
     ]
    }
   ],
   "source": [
    "time.tic()\n",
    "y_tilde_hat = clf.predict(X_test)\n",
    "time.toc(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 255)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tilde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 255)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tilde_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4435448603683898"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest prediction error\n",
    "1-(y_test_tilde == y_tilde_hat).sum() / float(y_test_tilde.shape[0] * y_test_tilde.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18396632996633"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest prediction error for embedding bits\n",
    "1-(y_test_tilde[:, :45] == y_tilde_hat[:, :45]).sum() / float(y_test_tilde[:, :45].shape[0] * y_test_tilde[:, :45].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49919240249383789"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest prediction error for parity bits\n",
    "1-(y_test_tilde[:, 46:] == y_tilde_hat[:, 46:]).sum() / float(y_test_tilde[:, 46:].shape[0] * y_test_tilde[:, 46:].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "savemat(file_name=\"../.temp/test/y_tilde_hat\", \n",
    "        mdict={'y_tilde_hats':[y_tilde_hat],\n",
    "               'L_bar':L_bar\n",
    "              }\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300, 255)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tilde_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Using **Matlab** to decode $\\hat{\\tilde y}$ into $\\hat{\\bar y}$ ...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the y_tilde file generated by matlab\n",
    "from scipy.io import savemat, loadmat\n",
    "y_bar_hats = loadmat(\"../.temp/test/y_bar_hat.mat\")['y_bar_hats'].astype(int)\n",
    "y_bar_hat = y_bar_hats[0]\n",
    "#y_bar_hat = clf_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use KNN searcher to recover the predicted y_hat\n",
    "dist, ind = nn_index.search(np.ascontiguousarray(y_bar_hat.astype('float32')), voter)\n",
    "y_hat = np.stack([\n",
    "    np.sum(np.array([\n",
    "        y_train[indij].astype('float32')/float(distij**2 + 0.01) for indij, distij in zip(indi, disti)\n",
    "    ]), axis=0)\n",
    "    for indi, disti in zip(ind, dist)\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_at_k(truth, vote, k=1):\n",
    "    assert(truth.shape == vote.shape)\n",
    "    success = 0\n",
    "    for i in range(truth.shape[0]):\n",
    "        topk = np.argpartition(vote[i], -k)[-k:]\n",
    "        success += truth[i, topk].sum()\n",
    "    return success / ((float(truth.shape[0]))*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision_at_k(y_test, y_hat, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1-(y_test == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_bar == y_bar_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Results\n",
    "\n",
    "* random forest classifer for multi-label task\n",
    "\n",
    "$\\sigma$| p@1 | p@3 | p@5 \n",
    "  ---   | --- | --- | --- \n",
    "    0   | 0.126 | 0.107 | 0.099\n",
    "    0.1 | 0.112 | 0.091 | 0.085\n",
    "    0.4 | 0.063 | 0.061 | 0.059\n",
    "     \n",
    "* OvsA with logistic regression \n",
    "\n",
    "$\\sigma$| p@1 | p@3 | p@5 \n",
    "  ---   | --- | --- | --- \n",
    "    0   | 0.281  | 0.231 | 0.209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tilde_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
